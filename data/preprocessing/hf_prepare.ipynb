{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import transformers\n",
    "import os\n",
    "# proxy\n",
    "os.environ[\"http_proxy\"] = \"http://proxy.ad.speechpro.com:3128\"\n",
    "os.environ[\"https_proxy\"] = \"http://proxy.ad.speechpro.com:3128\"\n",
    "os.environ[\"ftp_proxy\"] = \"http://proxy.ad.speechpro.com:3128\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = transformers.AutoTokenizer.from_pretrained(\"cointegrated/rut5-small-chitchat2\", truncation_side='left', padding_side='right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = datasets.Dataset.from_json('/home/stc/persona/data/raw/TolokaPersonaChat(test).jsonl')\n",
    "train = datasets.Dataset.from_json('/home/stc/persona/data/raw/TolokaPersonaChat(train).jsonl')\n",
    "ds =  datasets.DatasetDict({\"train\": train, \"test\": test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_same_person(row):\n",
    "    dialog = row['dialog']\n",
    "    new_dialog = dialog[:1]\n",
    "    for d in dialog[1:]:\n",
    "        if new_dialog[-1][\"person\"] == d[\"person\"]:\n",
    "            new_dialog[-1][\"text\"] = new_dialog[-1][\"text\"] + \" \" + d[\"text\"]\n",
    "            new_dialog[-1][\"gk\"] = list(set(new_dialog[-1][\"gk\"]) | set(d[\"gk\"]))\n",
    "        else:\n",
    "            new_dialog.append(d)\n",
    "    return {\"dialog\": new_dialog}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gk_from_persona(row):\n",
    "    dialog = row['dialog']\n",
    "    persons = row['persons']\n",
    "    pocesed_dialog = []\n",
    "    for turn in dialog:\n",
    "        persona = persons[turn['person']]\n",
    "        gk = [persona['description'][i] for i in turn['gk']]\n",
    "        gender = persona['gender']\n",
    "        pocesed_dialog.append({\"text\": turn['text'], \"gks\": gk, \"gender\": gender})\n",
    "    return {\"dialog\": pocesed_dialog}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_answer_sampler(batch):\n",
    "    dialogs = batch['dialog']\n",
    "    historys=[]\n",
    "    answers=[]\n",
    "    gks = []\n",
    "    for dialog in dialogs:\n",
    "        for turn_i in range(1, len(dialog)):\n",
    "            history = dialog[: turn_i]\n",
    "            answer = dialog[turn_i]\n",
    "            gk = dialog[turn_i][\"gks\"]\n",
    "            historys.append(history)\n",
    "            if len(gk)==0:\n",
    "                gk = [\"<EmptyGK>\"]\n",
    "            gks.append(gk)\n",
    "            answers.append(answer)\n",
    "    [[turn.pop('gks', 0) for turn in dialog] for dialog in historys]\n",
    "    [answer.pop('gks', 0) for answer in answers]\n",
    "    return {\"history\": historys, \"gk\": gks, \"answer\": answers}\n",
    "\n",
    "def current_gk_sampler(batch):\n",
    "    dialogs = batch['dialog']\n",
    "    turns=[]\n",
    "    gks=[]\n",
    "    for dialog in dialogs:\n",
    "        for turn in dialog:\n",
    "            if len(turn['gks'])>0:\n",
    "                for gk in turn['gks']:\n",
    "                    turns.append(turn)\n",
    "                    gks.append(gk)\n",
    "            else:\n",
    "                turns.append(turn)\n",
    "                gks.append('<EmptyGK>')\n",
    "    [turn.pop('gks', 0) for turn in turns]  \n",
    "    return {\"turn\": turns, \"gk\": gks}\n",
    "\n",
    "\n",
    "def next_gk_sampler(batch):\n",
    "    dialogs = batch['dialog']\n",
    "    historys=[]\n",
    "    gks = []\n",
    "    all_gks=[]\n",
    "    for dialog in dialogs:\n",
    "        for turn_i in range(1, len(dialog)):\n",
    "            history = dialog[: turn_i]\n",
    "            answer = dialog[turn_i]\n",
    "            if len(answer['gks'])>0:\n",
    "                for gk in answer['gks']:\n",
    "                    historys.append(history)\n",
    "                    gks.append(gk)\n",
    "                    all_gks.append(answer['gks'])\n",
    "            else:\n",
    "                historys.append(history)\n",
    "                gks.append('<EmptyGK>')\n",
    "                all_gks.append(['<EmptyGK>'])\n",
    "            \n",
    "    [[turn.pop('gks', 0) for turn in dialog] for dialog in historys]\n",
    "    return {\"history\": historys, \"gk\": gks, \"all_gks\": all_gks}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_ds = ds.map(join_same_person)\n",
    "new_ds = new_ds.map(get_gk_from_persona, remove_columns=[\"persons\"])\n",
    "\n",
    "next_answer_ds= new_ds.map(next_answer_sampler, remove_columns=new_ds['train'].column_names, batched=True, batch_size=2)\n",
    "current_gk_ds= new_ds.map(current_gk_sampler, remove_columns=new_ds['train'].column_names, batched=True, batch_size=2)\n",
    "next_gk_ds= new_ds.map(next_gk_sampler, remove_columns=new_ds['train'].column_names, batched=True, batch_size=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_answer_ds.save_to_disk('next_answer')\n",
    "current_gk_ds.save_to_disk('current_gk')\n",
    "next_gk_ds.save_to_disk('next_gk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_gk_ds['train'][159]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "asr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "191dbb9e29aa279379529ac18f64856cdae5eba81ec3175c8cc481ac2a196107"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
