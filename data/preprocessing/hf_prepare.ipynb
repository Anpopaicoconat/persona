{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import transformers\n",
    "import os\n",
    "# proxy\n",
    "os.environ[\"http_proxy\"] = \"http://proxy.ad.speechpro.com:3128\"\n",
    "os.environ[\"https_proxy\"] = \"http://proxy.ad.speechpro.com:3128\"\n",
    "os.environ[\"ftp_proxy\"] = \"http://proxy.ad.speechpro.com:3128\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_same_person(row):\n",
    "    dialog = row['dialog']\n",
    "    new_dialog = dialog[:1]\n",
    "    for d in dialog[1:]:\n",
    "        if new_dialog[-1][\"person\"] == d[\"person\"]:\n",
    "            new_dialog[-1][\"text\"] = new_dialog[-1][\"text\"] + \" \" + d[\"text\"]\n",
    "            new_dialog[-1][\"gk\"] = list(set(new_dialog[-1][\"gk\"]) | set(d[\"gk\"]))\n",
    "        else:\n",
    "            new_dialog.append(d)\n",
    "    return {\"dialog\": new_dialog}\n",
    "\n",
    "def get_gk_from_persona(row):\n",
    "    dialog = row['dialog']\n",
    "    persons = row['persons']\n",
    "    pocesed_dialog = []\n",
    "    for turn in dialog:\n",
    "        persona = persons[turn['person']]\n",
    "        gk = [persona['description'][i] for i in turn['gk']]\n",
    "        gender = persona['gender']\n",
    "        pocesed_dialog.append({\"text\": turn['text'], \"gks\": gk, \"gender\": gender})\n",
    "    return {\"dialog\": pocesed_dialog}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_answer_sampler(batch):\n",
    "    dialogs = batch['dialog']\n",
    "    historys=[]\n",
    "    answers=[]\n",
    "    gks = []\n",
    "    for dialog in dialogs:\n",
    "        for turn_i in range(1, len(dialog)):\n",
    "            history = dialog[: turn_i]\n",
    "            answer = dialog[turn_i]\n",
    "            gk = dialog[turn_i][\"gks\"]\n",
    "            historys.append(history)\n",
    "            if len(gk)==0:\n",
    "                gk = [\"<EmptyGK>\"]\n",
    "            gks.append(gk)\n",
    "            answers.append(answer)\n",
    "    [[turn.pop('gks', 0) for turn in dialog] for dialog in historys]\n",
    "    [answer.pop('gks', 0) for answer in answers]\n",
    "    return {\"history\": historys, \"gk\": gks, \"answer\": answers}\n",
    "\n",
    "def current_gk_sampler(batch):\n",
    "    dialogs = batch['dialog']\n",
    "    turns=[]\n",
    "    gks=[]\n",
    "    for dialog in dialogs:\n",
    "        for turn in dialog:\n",
    "            if len(turn['gks'])>0:\n",
    "                turns.append(turn)\n",
    "                gks.append(turn['gks'])\n",
    "            else:\n",
    "                turns.append(turn)\n",
    "                gks.append({'<EmptyGK>'})\n",
    "    [turn.pop('gks', 0) for turn in turns]  \n",
    "    return {\"turn\": turns, \"gk\": gks}\n",
    "\n",
    "\n",
    "def next_gk_sampler(batch):\n",
    "    dialogs = batch['dialog']\n",
    "    historys=[]\n",
    "    gks = []\n",
    "    all_gks=[]\n",
    "    for dialog in dialogs:\n",
    "        for turn_i in range(1, len(dialog)):\n",
    "            history = dialog[: turn_i]\n",
    "            answer = dialog[turn_i]\n",
    "            if len(answer['gks'])>0:\n",
    "                for gk in answer['gks']:\n",
    "                    historys.append(history)\n",
    "                    gks.append(gk)\n",
    "                    all_gks.append(answer['gks'])\n",
    "            else:\n",
    "                historys.append(history)\n",
    "                gks.append('<EmptyGK>')\n",
    "                all_gks.append(['<EmptyGK>'])\n",
    "            \n",
    "    [[turn.pop('gks', 0) for turn in dialog] for dialog in historys]\n",
    "    return {\"history\": historys, \"gk\": gks, \"all_gks\": all_gks}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-71063147b23792f3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset json/default to /home/posokhov@ad.speechpro.com/.cache/huggingface/datasets/json/default-71063147b23792f3/0.0.0...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data files: 100%|██████████| 1/1 [00:00<00:00, 9177.91it/s]\n",
      "Extracting data files: 100%|██████████| 1/1 [00:00<00:00, 1431.01it/s]\n",
      "Using custom data configuration default-e6f074a4bf715248\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset json downloaded and prepared to /home/posokhov@ad.speechpro.com/.cache/huggingface/datasets/json/default-71063147b23792f3/0.0.0. Subsequent calls will reuse this data.\n",
      "Downloading and preparing dataset json/default to /home/posokhov@ad.speechpro.com/.cache/huggingface/datasets/json/default-e6f074a4bf715248/0.0.0...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data files: 100%|██████████| 1/1 [00:00<00:00, 2138.86it/s]\n",
      "Extracting data files: 100%|██████████| 1/1 [00:00<00:00, 629.30it/s]\n",
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset json downloaded and prepared to /home/posokhov@ad.speechpro.com/.cache/huggingface/datasets/json/default-e6f074a4bf715248/0.0.0. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9018/9018 [00:02<00:00, 3283.38ex/s]\n",
      "100%|██████████| 995/995 [00:00<00:00, 4130.32ex/s]\n",
      "100%|██████████| 9018/9018 [00:02<00:00, 4107.94ex/s]\n",
      "100%|██████████| 995/995 [00:00<00:00, 4097.61ex/s]\n",
      "100%|██████████| 4509/4509 [00:06<00:00, 715.32ba/s]\n",
      "100%|██████████| 498/498 [00:00<00:00, 767.97ba/s]\n",
      "100%|██████████| 4509/4509 [00:03<00:00, 1291.10ba/s]\n",
      "100%|██████████| 498/498 [00:00<00:00, 1297.67ba/s]\n",
      "100%|██████████| 4509/4509 [00:05<00:00, 841.78ba/s]\n",
      "100%|██████████| 498/498 [00:00<00:00, 816.46ba/s]\n"
     ]
    }
   ],
   "source": [
    "train = datasets.Dataset.from_json('../raw/TolokaPersonaChat(train).jsonl')\n",
    "val = datasets.Dataset.from_json('../raw/TolokaPersonaChat(val).jsonl')\n",
    "#test = datasets.Dataset.from_json('../raw/all_dialogs.jsonl')\n",
    "ds =  datasets.DatasetDict({\"train\": train, \"val\":val}) # , \"test\": test\n",
    "\n",
    "new_ds = ds.map(join_same_person)\n",
    "new_ds = new_ds.map(get_gk_from_persona, remove_columns=[\"persons\"])\n",
    "\n",
    "next_answer_ds= new_ds.map(next_answer_sampler, remove_columns=new_ds['train'].column_names, batched=True, batch_size=2)\n",
    "current_gk_ds= new_ds.map(current_gk_sampler, remove_columns=new_ds['train'].column_names, batched=True, batch_size=2)\n",
    "next_gk_ds= new_ds.map(next_gk_sampler, remove_columns=new_ds['train'].column_names, batched=True, batch_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_answer_ds.save_to_disk('../processed/next_answer')\n",
    "current_gk_ds.save_to_disk('../processed/current_gk')\n",
    "next_gk_ds.save_to_disk('../processed/next_gk')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "asr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "191dbb9e29aa279379529ac18f64856cdae5eba81ec3175c8cc481ac2a196107"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
