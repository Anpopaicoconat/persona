{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stc/rybin-as/miniconda3/envs/asr/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import datasets\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import transformers\n",
    "import os\n",
    "# proxy\n",
    "os.environ[\"http_proxy\"] = \"http://proxy.ad.speechpro.com:3128\"\n",
    "os.environ[\"https_proxy\"] = \"http://proxy.ad.speechpro.com:3128\"\n",
    "os.environ[\"ftp_proxy\"] = \"http://proxy.ad.speechpro.com:3128\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_same_person(row):\n",
    "    dialog = row['dialog']\n",
    "    new_dialog = dialog[:1]\n",
    "    for d in dialog[1:]:\n",
    "        if new_dialog[-1][\"person\"] == d[\"person\"]:\n",
    "            new_dialog[-1][\"text\"] = new_dialog[-1][\"text\"] + \" \" + d[\"text\"]\n",
    "            new_dialog[-1][\"gk\"] = list(set(new_dialog[-1][\"gk\"]) | set(d[\"gk\"]))\n",
    "        else:\n",
    "            new_dialog.append(d)\n",
    "    return {\"dialog\": new_dialog}\n",
    "\n",
    "def get_gk_from_persona(row):\n",
    "    dialog = row['dialog']\n",
    "    persons = row['persons']\n",
    "    pocesed_dialog = []\n",
    "    for turn in dialog:\n",
    "        persona = persons[turn['person']]\n",
    "        gk = [persona['description'][i] for i in turn['gk']]\n",
    "        gender = persona['gender']\n",
    "        pocesed_dialog.append({\"text\": turn['text'], \"gks\": gk, \"gender\": gender})\n",
    "    return {\"dialog\": pocesed_dialog}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_answer_sampler(batch):\n",
    "    dialogs = batch['dialog']\n",
    "    historys=[]\n",
    "    answers=[]\n",
    "    gks = []\n",
    "    for dialog in dialogs:\n",
    "        for turn_i in range(1, len(dialog)):\n",
    "            history = dialog[: turn_i]\n",
    "            answer = dialog[turn_i]\n",
    "            gk = dialog[turn_i][\"gks\"]\n",
    "            historys.append(history)\n",
    "            if len(gk)==0:\n",
    "                gk = [\"<EmptyGK>\"]\n",
    "            gks.append(gk)\n",
    "            answers.append(answer)\n",
    "    [[turn.pop('gks', 0) for turn in dialog] for dialog in historys]\n",
    "    [answer.pop('gks', 0) for answer in answers]\n",
    "    return {\"history\": historys, \"gk\": gks, \"answer\": answers}\n",
    "\n",
    "def current_gk_sampler(batch):\n",
    "    dialogs = batch['dialog']\n",
    "    turns=[]\n",
    "    gks=[]\n",
    "    for dialog in dialogs:\n",
    "        for turn in dialog:\n",
    "            if len(turn['gks'])>0:\n",
    "                turns.append(turn)\n",
    "                gks.append(turn['gks'])\n",
    "            else:\n",
    "                turns.append(turn)\n",
    "                gks.append({'<EmptyGK>'})\n",
    "    [turn.pop('gks', 0) for turn in turns]  \n",
    "    return {\"turn\": turns, \"gk\": gks}\n",
    "\n",
    "\n",
    "def next_gk_sampler(batch):\n",
    "    dialogs = batch['dialog']\n",
    "    historys=[]\n",
    "    gks = []\n",
    "    all_gks=[]\n",
    "    for dialog in dialogs:\n",
    "        for turn_i in range(1, len(dialog)):\n",
    "            history = dialog[: turn_i]\n",
    "            answer = dialog[turn_i]\n",
    "            if len(answer['gks'])>0:\n",
    "                for gk in answer['gks']:\n",
    "                    historys.append(history)\n",
    "                    gks.append(gk)\n",
    "                    all_gks.append(answer['gks'])\n",
    "            else:\n",
    "                historys.append(history)\n",
    "                gks.append('<EmptyGK>')\n",
    "                all_gks.append(['<EmptyGK>'])\n",
    "            \n",
    "    [[turn.pop('gks', 0) for turn in dialog] for dialog in historys]\n",
    "    return {\"history\": historys, \"gk\": gks, \"all_gks\": all_gks}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-1af070eac410af7a\n",
      "Found cached dataset json (/home/stc/.cache/huggingface/datasets/json/default-1af070eac410af7a/0.0.0)\n",
      "Using custom data configuration default-5e9c8dcf8ec784b4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset json/default to /home/stc/.cache/huggingface/datasets/json/default-5e9c8dcf8ec784b4/0.0.0...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data files: 100%|██████████| 1/1 [00:00<00:00, 1747.63it/s]\n",
      "Extracting data files: 100%|██████████| 1/1 [00:00<00:00, 981.12it/s]\n",
      "Using custom data configuration default-2ff60e14f8a9aaf2\n",
      "Found cached dataset json (/home/stc/.cache/huggingface/datasets/json/default-2ff60e14f8a9aaf2/0.0.0)\n",
      "Loading cached processed dataset at /home/stc/.cache/huggingface/datasets/json/default-1af070eac410af7a/0.0.0/cache-d5194342dc43ee8e.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset json downloaded and prepared to /home/stc/.cache/huggingface/datasets/json/default-5e9c8dcf8ec784b4/0.0.0. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 995/995 [00:00<00:00, 3288.03ex/s]     \n",
      "Loading cached processed dataset at /home/stc/.cache/huggingface/datasets/json/default-2ff60e14f8a9aaf2/0.0.0/cache-d4de3b0d3441b2a2.arrow\n",
      "Loading cached processed dataset at /home/stc/.cache/huggingface/datasets/json/default-1af070eac410af7a/0.0.0/cache-26a6018c23d9b2c1.arrow\n",
      "100%|██████████| 995/995 [00:00<00:00, 4959.61ex/s]\n",
      "Loading cached processed dataset at /home/stc/.cache/huggingface/datasets/json/default-2ff60e14f8a9aaf2/0.0.0/cache-c309b83101ac6d7f.arrow\n",
      "Loading cached processed dataset at /home/stc/.cache/huggingface/datasets/json/default-1af070eac410af7a/0.0.0/cache-b8e8ffa364c75536.arrow\n",
      "100%|██████████| 498/498 [00:00<00:00, 749.91ba/s]\n",
      "Loading cached processed dataset at /home/stc/.cache/huggingface/datasets/json/default-2ff60e14f8a9aaf2/0.0.0/cache-03d7d1165b66f479.arrow\n",
      "Loading cached processed dataset at /home/stc/.cache/huggingface/datasets/json/default-1af070eac410af7a/0.0.0/cache-ecb3337faa8291d3.arrow\n",
      "100%|██████████| 498/498 [00:00<00:00, 1258.50ba/s]\n",
      "Loading cached processed dataset at /home/stc/.cache/huggingface/datasets/json/default-2ff60e14f8a9aaf2/0.0.0/cache-92f2aa068ebbabf8.arrow\n",
      "Loading cached processed dataset at /home/stc/.cache/huggingface/datasets/json/default-1af070eac410af7a/0.0.0/cache-9ac2729207ff2704.arrow\n",
      "100%|██████████| 498/498 [00:00<00:00, 847.47ba/s]\n",
      "Loading cached processed dataset at /home/stc/.cache/huggingface/datasets/json/default-2ff60e14f8a9aaf2/0.0.0/cache-5f8f1288111ec319.arrow\n"
     ]
    }
   ],
   "source": [
    "train = datasets.Dataset.from_json('/home/stc/persona/data/raw/TolokaPersonaChat(train).jsonl')\n",
    "val = datasets.Dataset.from_json('/home/stc/persona/data/raw/TolokaPersonaChat(val).jsonl')\n",
    "test = datasets.Dataset.from_json('/home/stc/persona/data/raw/all_dialogs.jsonl')\n",
    "ds =  datasets.DatasetDict({\"train\": train, \"val\":val, \"test\": test})\n",
    "\n",
    "new_ds = ds.map(join_same_person)\n",
    "new_ds = new_ds.map(get_gk_from_persona, remove_columns=[\"persons\"])\n",
    "\n",
    "next_answer_ds= new_ds.map(next_answer_sampler, remove_columns=new_ds['train'].column_names, batched=True, batch_size=2)\n",
    "current_gk_ds= new_ds.map(current_gk_sampler, remove_columns=new_ds['train'].column_names, batched=True, batch_size=2)\n",
    "next_gk_ds= new_ds.map(next_gk_sampler, remove_columns=new_ds['train'].column_names, batched=True, batch_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                   \r"
     ]
    }
   ],
   "source": [
    "next_answer_ds.save_to_disk('/home/stc/persona/data/next_answer')\n",
    "current_gk_ds.save_to_disk('/home/stc/persona/data/current_gk')\n",
    "next_gk_ds.save_to_disk('/home/stc/persona/data/next_gk')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "asr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "191dbb9e29aa279379529ac18f64856cdae5eba81ec3175c8cc481ac2a196107"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
